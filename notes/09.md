# async web application

ASGI vs WSGI

- Using ASGI with Starlette
- Django async views

RUN

- https://github.com/encode/uvicorn

## run listing_9_5.py

- postgre database is installed in Windows OS
- run python code in WSL2

1. get WSL IP：

```
以太网适配器 vEthernet (WSL):

   连接特定的 DNS 后缀 . . . . . . . :
   本地链接 IPv6 地址. . . . . . . . : fe80::ce7b:a737:d02a:ac56%51
   IPv4 地址 . . . . . . . . . . . . : 172.30.64.1
   子网掩码  . . . . . . . . . . . . : 255.255.240.0
   默认网关. . . . . . . . . . . . . :
```

2. edit `C:\Program Files\PostgreSQL\9.5\data\pg_hba.conf`

```conf
# IPv4 local connections:
host    all             all             127.0.0.1/32            md5
host    all             all             172.30.64.0/24           md5
host    all             all             192.0.0.0/8             md5
```

3. restart postgresql you can restart postgresql from `services.msc.`
   service name is `postgresql-x64-{postgresqlVersion}`.

4. connect:

> https://stackoverflow.com/a/41161674

```bash
psql -h 172.30.64.1 -p 5432 -U postgres
```

- 以太网适配器 vEthernet (WSL): 172.30.64.1 这个 IP 每次 windows 重启都会变更，因为 WSL 配置不持久，而是销毁重建的。
- 以太网适配器 vEthernet (WLAN): 172.23.112.1 这个 IP 是 WSL 的虚拟 WLAN 地址。是否变更有待观察。
- 使用 windows 宿主的 IP（例如无线局域网适配器 WLAN）更好，也能链接，一般不会改变，比较稳定。

Then change the ip in conn_info string in `listing_9_5.py` to 172.30.64.1.

5. run python web app.

```bash
wdpm@DESKTOP-QLDBOG2:/mnt/d/Code/OtherGithubProjects/concurrency-in-python-with-asyncio$ gunicorn -w 8 chapter_09.listing_9_5:app
[2023-01-10 20:58:45 +0800] [8305] [INFO] Starting gunicorn 20.1.0
[2023-01-10 20:58:45 +0800] [8305] [INFO] Listening at: http://127.0.0.1:8000 (8305)
[2023-01-10 20:58:45 +0800] [8305] [INFO] Using worker: sync
[2023-01-10 20:58:45 +0800] [8307] [INFO] Booting worker with pid: 8307
[2023-01-10 20:58:45 +0800] [8308] [INFO] Booting worker with pid: 8308
[2023-01-10 20:58:45 +0800] [8309] [INFO] Booting worker with pid: 8309
[2023-01-10 20:58:45 +0800] [8310] [INFO] Booting worker with pid: 8310
[2023-01-10 20:58:45 +0800] [8311] [INFO] Booting worker with pid: 8311
[2023-01-10 20:58:45 +0800] [8312] [INFO] Booting worker with pid: 8312
[2023-01-10 20:58:45 +0800] [8313] [INFO] Booting worker with pid: 8313
[2023-01-10 20:58:45 +0800] [8314] [INFO] Booting worker with pid: 8314
```

8307-8314 表示 8 个 worker 的运行 pid。

## benchmark test

We’ll use a load tester called wrk, though any load tester, such as Apache Bench or Hey, will work.
You can view installation instructions on wrk at `https://github.com/wg/wrk`.

这里我们需要下载 wrk 的 git 源码仓库到本地进行编译链接，但是 WSL 本身无法访问外网 github。于是需要设置合适的代理。

参考这篇文章：https://zinglix.xyz/2020/04/18/wsl2-proxy/。最后，注意要放开 windows 宿主的防火墙，关闭或者设置规则都可以。

---

编译 wrk

```bash
sudo apt install build-essential libssl-dev git unzip
git clone git@github.com:wg/wrk.git

cd wrk
# 这步需要等很久
make
# 把生成的 wrk 移到一个 PATH 目录下面
sudo cp wrk /usr/local/bin
```

---

- 使用 gunicorn -w 8 chapter_09.listing_9_5:app 启动基于 flask 的 app
- 使用 python3 chapter_09.listing_9_2:app 直接启动基于 aiohttp 的 app

先后使用 command 进行测试：
```bash
wrk -t1 -c200 -d30s http://127.0.0.1:8000/brands
```
This runs a benchmark for 30 seconds, using 1 threads, and keeping 200 HTTP connections open.

基于 flask 的 app 的测试结果：
```bash
wdpm@DESKTOP-QLDBOG2:~/wrk$ wrk -t1 -c200 -d30s http://127.0.0.1:8000/brands
Running 30s test @ http://127.0.0.1:8000/brands
  1 threads and 200 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    99.76ms   17.49ms 191.77ms   69.21%
    Req/Sec     2.00k   333.86     2.55k    61.54%
  59945 requests in 30.07s, 462.15MB read
Requests/sec:   1993.48
Transfer/sec:     15.37MB
```
此时，务必杀掉占用 8000 端口的旧进程，然后再次使用 gunicorn 启动 app。

---

```bash
python3 chapter_09.listing_9_2:app 
```

基于 aiohttp 的 app 的测试结果：
```bash
wdpm@DESKTOP-QLDBOG2:~/wrk$ wrk -t1 -c200 -d30s http://127.0.0.1:8080/brands
Running 30s test @ http://127.0.0.1:8080/brands
  1 threads and 200 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   218.02ms  137.27ms   1.51s    70.70%
    Req/Sec     0.94k   154.43     1.15k    73.88%
  27423 requests in 30.03s, 233.54MB read
  Socket errors: connect 0, read 280, write 29907, timeout 0
Requests/sec:    913.11
Transfer/sec:      7.78MB
```

也就是 flask(8 workers) 接近 2000 Requests/sec，整体上此时优于 1 worker 的 aiohttp，913.11 Requests/sec。

如果从平均来看， flask 250 rq /worker/sec，弱于 aiohttp 的 ≈900 Requests/sec。

个人实验的结果和作者的非常不同。作者的结果是 [1 worker 的 aiohttp] 优于 [8 worker 的 gunicorn + flask]。
推测结果不同的原因：作者的电脑设备，以及使用的软件版本和我的不一致。

作者在书中给出了 aiohttp 使用多 worker 的方法，加一个前置的反向代理 web 服务器 nginx。

>  You could further improve the performance of aiohttp by putting NGINX in front of it and starting more worker processes.

## simple wsgi app
```python
def application(env, start_response):
    start_response('200 OK', [('Content-Type','text/html')])
    return [b"WSGI hello!"]
```
```bash
gunicorn chapter_09.listing_9_6
```
```bash
wdpm  ~  ♥ 11:55  curl http://127.0.0.1:8000


StatusCode        : 200
StatusDescription : OK
Content           : WSGI hello!
RawContent        : HTTP/1.1 200 OK
                    Connection: close
                    Transfer-Encoding: chunked
                    Content-Type: text/html
                    Date: Thu, 12 Jan 2023 03:55:33 GMT
                    Server: gunicorn

                    WSGI hello!
```

## simple ASGI app
```bash
pip install uvicorn
uvicorn chapter_09.listing_9_7:application
```
```bash
wdpm  ~  ♥ 11:55  curl http://127.0.0.1:8000


StatusCode        : 200
StatusDescription : OK
Content           : ASGI hello!
RawContent        : HTTP/1.1 200 OK
                    Transfer-Encoding: chunked
                    Content-Type: text/html
                    Date: Thu, 12 Jan 2023 03:58:39 GMT
                    Server: uvicorn

                    ASGI hello!
```

## ASGI with Starlette

```bash
$ uvicorn --workers 8 --log-level info chapter_09.listing_9_8:app
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:     Started parent process [492]
INFO:     Started server process [498]
INFO:     Waiting for application startup.
INFO:     Started server process [495]
INFO:     Started server process [497]
INFO:     Waiting for application startup.
INFO:     Waiting for application startup.
INFO:     Started server process [494]
INFO:     Waiting for application startup.
INFO:     Started server process [500]
INFO:     Waiting for application startup.
INFO:     Started server process [499]
INFO:     Waiting for application startup.
INFO:     Started server process [501]
INFO:     Waiting for application startup.
INFO:     Started server process [496]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Application startup complete.
INFO:     Application startup complete.
INFO:     Application startup complete.
INFO:     Application startup complete.
INFO:     Application startup complete.
INFO:     Application startup complete.
INFO:     Application startup complete.
```

```bash
wdpm@DESKTOP-QLDBOG2:~$ wrk -t1 -c200 -d30s http://127.0.0.1:8000/brands
Running 30s test @ http://127.0.0.1:8000/brands
  1 threads and 200 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   269.62ms  297.56ms   2.00s    85.99%
    Req/Sec     0.98k   212.73     1.41k    64.31%
  29220 requests in 30.07s, 224.69MB read
  Socket errors: connect 0, read 0, write 0, timeout 55
Requests/sec:    971.67
Transfer/sec:      7.47MB
```

## starlette with websocket
```bash
$ uvicorn --workers 1 chapter_09.listing_9_9:app
INFO:     Started server process [540]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:     ('127.0.0.1', 56272) - "WebSocket /counter" [accepted]
INFO:     connection open
INFO:     ('127.0.0.1', 56274) - "WebSocket /counter" [accepted]
INFO:     connection open
INFO:     ('127.0.0.1', 56276) - "WebSocket /counter" [accepted]
INFO:     connection open
```
上面是打开三个 chrome tab 页面的结果。
```
Users online: 3
```

然后关闭两个页面，结果如下：
```bash
INFO:     connection closed
INFO:     connection closed
```
```
Users online: 1
```

> Note that we only use one worker here, as we have shared state (the socket list)
in memory; if we use multiple workers, each worker will have its own socket list. To
deploy properly, you’ll need some persistent store, such as a database.


## Django asynchronous views
Django 3.1+, 开始引入 async 视图。

Run the following command from the top-level async_views directory:
```bash
# uvicorn async_views.asgi:application 
gunicorn async_views.asgi:application -k uvicorn.workers.UvicornWorker
```
```bash
$ gunicorn async_views.asgi:application -k uvicorn.workers.UvicornWorker
[2023-01-12 15:06:54 +0800] [659] [INFO] Starting gunicorn 20.1.0
[2023-01-12 15:06:54 +0800] [659] [INFO] Listening at: http://127.0.0.1:8000 (659)
[2023-01-12 15:06:54 +0800] [659] [INFO] Using worker: uvicorn.workers.UvicornWorker
[2023-01-12 15:06:54 +0800] [660] [INFO] Booting worker with pid: 660
[2023-01-12 07:06:55 +0000] [660] [INFO] Started server process [660]
[2023-01-12 07:06:55 +0000] [660] [INFO] Waiting for application startup.
[2023-01-12 07:06:55 +0000] [660] [INFO] ASGI 'lifespan' protocol appears unsupported.
[2023-01-12 07:06:55 +0000] [660] [INFO] Application startup complete.
```

### wsgi
先观察 wsgi 1 worker 的性能结果：
```bash
gunicorn async_views.wsgi:application
```
```bash
http://localhost:8000/requests/?url=http://example.com&request_num=2
```
wsgi在请求数量大于1时都是超时，后台观测到worker被不断销毁，然后重建。
```bash
$ gunicorn async_views.wsgi:application
[2023-01-12 15:34:22 +0800] [740] [INFO] Starting gunicorn 20.1.0
[2023-01-12 15:34:22 +0800] [740] [INFO] Listening at: http://127.0.0.1:8000 (740)
[2023-01-12 15:34:22 +0800] [740] [INFO] Using worker: sync
[2023-01-12 15:34:22 +0800] [741] [INFO] Booting worker with pid: 741
[2023-01-12 15:34:53 +0800] [740] [CRITICAL] WORKER TIMEOUT (pid:741)
[2023-01-12 07:34:53 +0000] [741] [INFO] Worker exiting (pid: 741)
[2023-01-12 15:34:54 +0800] [740] [WARNING] Worker with pid 741 was terminated due to signal 9
[2023-01-12 15:34:54 +0800] [745] [INFO] Booting worker with pid: 745
[2023-01-12 15:37:25 +0800] [740] [CRITICAL] WORKER TIMEOUT (pid:745)
[2023-01-12 07:37:25 +0000] [745] [INFO] Worker exiting (pid: 745)
[2023-01-12 15:37:26 +0800] [740] [WARNING] Worker with pid 745 was terminated due to signal 9
[2023-01-12 15:37:26 +0800] [757] [INFO] Booting worker with pid: 757
```

### asgi

```bash
gunicorn async_views.asgi:application --log-level=debug -k uvicorn.workers.UvicornWorker --log-file - --timeout 60
```
```bash
http://localhost:8000/requests/?url=http://example.com&request_num=2
```
request_num > 1时依旧超时挂起，不能正常工作。

### sync_to_async

```bash
curl http://127.0.0.1:8000/requests/sync_to_async?sleep_time=5&num_calls=5&thread_sensitive=False
```

依旧超时无效。

### async_to_sync

```bash
http://localhost:8000/requests/async_to_sync?url=http://example.com&request_num=2
```

依旧超时无效。
